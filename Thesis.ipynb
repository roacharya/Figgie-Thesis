{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d2684-02d5-440f-8ecc-078bc5b41f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import json\n",
    "!pip install trl==0.11\n",
    "import torch\n",
    "from datasets import Dataset, load_from_disk, DatasetDict\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, PreTrainedTokenizerFast, Trainer, TrainingArguments\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import os\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8a1b7-6a50-4e1b-8d0c-ba243af05643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self, player_id: int, side: str, suit: str, price: int):\n",
    "        \"\"\"\n",
    "        side: 'bid' or 'offer'\n",
    "        suit: one of 'spades', 'clubs', 'hearts', 'diamonds'\n",
    "        price: integer price\n",
    "        \"\"\"\n",
    "        self.player_id = player_id\n",
    "        self.side = side\n",
    "        self.suit = suit\n",
    "        self.price = price\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {\"player\": self.player_id, \"side\": self.side, \"suit\": self.suit, \"price\": self.price}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Order(p={self.player_id}, side={self.side}, suit={self.suit}, price={self.price})\"\n",
    "\n",
    "class OrderBook:\n",
    "    def __init__(self, suit: str, side: str):\n",
    "        self.suit = suit\n",
    "        self.side = side  # 'bid' or 'offer'\n",
    "        self.orders: Dict[int, Order] = {}  # price -> Order\n",
    "\n",
    "    def get_best(self) -> Optional[Order]:\n",
    "        if not self.orders:\n",
    "            return None\n",
    "        if self.side == 'bid':\n",
    "            best_price = max(self.orders.keys())\n",
    "        else:\n",
    "            best_price = min(self.orders.keys())\n",
    "        return self.orders[best_price]\n",
    "\n",
    "    def add_order(self, order: Order) -> bool:\n",
    "        if order.price in self.orders:\n",
    "            return False\n",
    "        self.orders[order.price] = order\n",
    "        return True\n",
    "\n",
    "    def cancel_order(self, player_id: int, price: int) -> bool:\n",
    "        order = self.orders.get(price)\n",
    "        if order and order.player_id == player_id:\n",
    "            del self.orders[price]\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.orders.clear()\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return {price: order.player_id for price, order in self.orders.items()}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"OrderBook(suit={self.suit}, side={self.side}): \" + \", \".join(str(o) for o in self.orders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9813a3a-dc97-4858-85dc-bf91e2716acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, player_id: int, name: Optional[str] = None, player_type: str = \"human\"):\n",
    "        self.player_id = player_id\n",
    "        self.name = name if name is not None else f\"Player_{player_id}\"\n",
    "        self.player_type = player_type  # \"human\" or \"bot\"\n",
    "        self.initial_chips = 350\n",
    "        self.chips = 350\n",
    "        self.initial_hand: Dict[str, int] = {}\n",
    "        self.hand: Dict[str, int] = {}\n",
    "        self.active_orders: List[Order] = []\n",
    "        self.pass_count = 0\n",
    "\n",
    "    def decide_action(self, public_state: dict) -> Tuple[str, dict]:\n",
    "        \"\"\"\n",
    "        Stub method. Override this method for human or RL agent play.\n",
    "        Returns a tuple (action_type, parameters)\n",
    "          For 'place': parameters = {'side': 'bid'/'offer', 'suit': <suit>, 'price': <int>}\n",
    "          For 'cancel': parameters = {'side': 'bid'/'offer', 'suit': <suit>, 'price': <int>}\n",
    "          For 'pass': parameters = {}\n",
    "        \"\"\"\n",
    "        return ('pass', {})\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}({self.player_type}, chips={self.chips})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76437aea-922e-49f4-ba84-afcd1e70da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    SUITS = ['spades', 'clubs', 'hearts', 'diamonds']\n",
    "    COLORS = {'spades': 'black', 'clubs': 'black', 'hearts': 'red', 'diamonds': 'red'}\n",
    "\n",
    "    # 12 predefined deck configurations.\n",
    "    DECK_CONFIGS = [\n",
    "        {'spades': 12, 'clubs': 10, 'hearts': 10, 'diamonds': 8},\n",
    "        {'spades': 12, 'clubs': 10, 'hearts': 8, 'diamonds': 10},\n",
    "        {'spades': 12, 'clubs': 8,  'hearts': 10, 'diamonds': 10},\n",
    "        {'clubs': 12,  'spades': 10, 'hearts': 10, 'diamonds': 8},\n",
    "        {'clubs': 12,  'spades': 10, 'hearts': 8,  'diamonds': 10},\n",
    "        {'clubs': 12,  'spades': 8,  'hearts': 10, 'diamonds': 10},\n",
    "        {'hearts': 12, 'diamonds': 10, 'spades': 10, 'clubs': 8},\n",
    "        {'hearts': 12, 'diamonds': 10, 'spades': 8,  'clubs': 10},\n",
    "        {'hearts': 12, 'diamonds': 8,  'spades': 10, 'clubs': 10},\n",
    "        {'diamonds': 12, 'hearts': 10, 'spades': 10, 'clubs': 8},\n",
    "        {'diamonds': 12, 'hearts': 10, 'spades': 8,  'clubs': 10},\n",
    "        {'diamonds': 12, 'hearts': 8,  'spades': 10, 'clubs': 10},\n",
    "    ]\n",
    "\n",
    "    def __init__(self, num_players: int = 4, seed: Optional[int] = None, round_number: int = 1, players: Optional[List[Player]] = None):\n",
    "        if num_players not in (4, 5):\n",
    "            raise ValueError(\"Only 4 or 5 players are allowed.\")\n",
    "        self.num_players = num_players\n",
    "        if players is not None:\n",
    "            if len(players) != num_players:\n",
    "                raise ValueError(\"Length of provided players list must match num_players.\")\n",
    "            self.players = players\n",
    "        else:\n",
    "            self.players: List[Player] = [Player(i, player_type=\"human\") for i in range(num_players)]\n",
    "        self.ante = 50 if num_players == 4 else 40\n",
    "        for p in self.players:\n",
    "            p.chips -= self.ante\n",
    "        self.pot = self.ante * num_players  # e.g., 200 for 4 players.\n",
    "\n",
    "        # Create order books.\n",
    "        self.order_books: Dict[Tuple[str, str], OrderBook] = {}\n",
    "        for suit in Game.SUITS:\n",
    "            for side in ['bid', 'offer']:\n",
    "                self.order_books[(suit, side)] = OrderBook(suit, side)\n",
    "\n",
    "        self.trade_history: List[dict] = []\n",
    "        self.turn_history: List[dict] = []\n",
    "        self.turn_number = 0\n",
    "        self.last_player_id: Optional[int] = None\n",
    "        self.game_over = False\n",
    "\n",
    "        # Game metadata.\n",
    "        self.game_id = random.randint(1, 1000000)\n",
    "        self.round_number = round_number\n",
    "        self.host = self.players[0].name\n",
    "        self.settings = {\n",
    "            \"hand_view\": \"Default\",\n",
    "            \"round_duration\": \"turn-based\",\n",
    "            \"minimum_number_of_players\": num_players\n",
    "        }\n",
    "        self.human_players = [p.name for p in self.players if p.player_type == \"human\"]\n",
    "        self.bot_players = [p.name for p in self.players if p.player_type == \"bot\"]\n",
    "\n",
    "        # Choose a deck configuration and deal.\n",
    "        self.deck_config = random.choice(Game.DECK_CONFIGS)\n",
    "        self.common_suit = [s for s, count in self.deck_config.items() if count == 12][0]\n",
    "        same_color = [s for s in Game.SUITS if Game.COLORS[s] == Game.COLORS[self.common_suit] and s != self.common_suit]\n",
    "        self.goal_suit = random.choice(same_color)\n",
    "        deck = []\n",
    "        for suit, count in self.deck_config.items():\n",
    "            deck.extend([suit] * count)\n",
    "        random.shuffle(deck)\n",
    "        cards_per_player = 10 if num_players == 4 else 8\n",
    "        self.starting_chips_and_hands = {}\n",
    "        for p in self.players:\n",
    "            p_cards = deck[:cards_per_player]\n",
    "            deck = deck[cards_per_player:]\n",
    "            hand = defaultdict(int)\n",
    "            for c in p_cards:\n",
    "                hand[c] += 1\n",
    "            p.hand = dict(hand)\n",
    "            p.initial_hand = dict(hand)\n",
    "            for suit in Game.SUITS:\n",
    "                if suit not in p.initial_hand:\n",
    "                    p.initial_hand[suit] = 0\n",
    "            self.starting_chips_and_hands[p.name] = {\"chips\": p.chips, \"hand\": dict(p.initial_hand)}\n",
    "\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        # NEW: Initialize pass-round tracking.\n",
    "        self.pass_round = 1  # Which round of passes we're in (1, 2, or 3)\n",
    "        self.passed_in_round = {p.player_id: False for p in self.players}\n",
    "\n",
    "    def clear_all_order_books(self) -> None:\n",
    "        for book in self.order_books.values():\n",
    "            book.clear()\n",
    "\n",
    "    def is_valid_place_order(self, player: Player, side: str, suit: str, price: int) -> Tuple[bool, str]:\n",
    "        if side not in ['bid', 'offer'] or suit not in Game.SUITS or not isinstance(price, int):\n",
    "            return False, \"format error\"\n",
    "        if side == 'offer' and player.hand.get(suit, 0) <= 0:\n",
    "            return False, \"no card to offer\"\n",
    "        if side == 'bid' and player.chips < price:\n",
    "          return False, \"insufficient chips\"\n",
    "        book = self.order_books[(suit, side)]\n",
    "        if price in book.orders:\n",
    "            return False, \"order already exists\"\n",
    "        if side == 'bid':\n",
    "            opposing = self.order_books[(suit, 'offer')]\n",
    "            best_offer = opposing.get_best()\n",
    "            if best_offer is None:\n",
    "                best_bid = self.order_books[(suit, 'bid')].get_best()\n",
    "                if best_bid and price <= best_bid.price:\n",
    "                    return False, \"does not improve bid/ask\"\n",
    "        elif side == 'offer':\n",
    "            opposing = self.order_books[(suit, 'bid')]\n",
    "            best_bid = opposing.get_best()\n",
    "            if best_bid is None:\n",
    "                best_offer = self.order_books[(suit, 'offer')].get_best()\n",
    "                if best_offer and price >= best_offer.price:\n",
    "                    return False, \"does not improve bid/ask\"\n",
    "        return True, \"\"\n",
    "\n",
    "    def get_action(self, player: Player) -> Tuple[str, dict]:\n",
    "        action = player.decide_action(self.get_public_state())\n",
    "        if action[0] == 'place':\n",
    "            side, suit, price = action[1].get('side'), action[1].get('suit'), action[1].get('price')\n",
    "            valid, reason = self.is_valid_place_order(player, side, suit, price)\n",
    "            if not valid and reason != \"does not improve bid/ask\":\n",
    "                print(f\"{player.name}: Order {action[1]} does not improve the bid/ask or is not placeable; treated as pass.\")\n",
    "                return ('pass', {})\n",
    "        if action[0] == 'cancel':\n",
    "            side, suit, price = action[1].get('side'), action[1].get('suit'), action[1].get('price')\n",
    "            book = self.order_books.get((suit, side))\n",
    "            if not (book and price in book.orders and book.orders[price].player_id == player.player_id):\n",
    "                # print(f\"{player.name}: Invalid cancel order {action[1]}. Turn skipped.\")\n",
    "                return ('invalid', {})\n",
    "        return action\n",
    "\n",
    "    def process_action(self, player: Player, action: Tuple[str, dict]) -> None:\n",
    "        self.turn_number += 1\n",
    "        event_time = datetime.now().isoformat()\n",
    "        action_type, params = action\n",
    "        turn_record = {\"turn\": self.turn_number,\n",
    "                       \"time\": event_time,\n",
    "                       \"player\": player.name,\n",
    "                       \"action\": action_type,\n",
    "                       \"params\": params}\n",
    "\n",
    "        if hasattr(player, \"last_prompt\"):\n",
    "            turn_record[\"prompt\"] = player.last_prompt\n",
    "        if hasattr(player, \"last_generated_action\"):\n",
    "            turn_record[\"last_generated_action\"] = player.last_generated_action\n",
    "\n",
    "        if action_type == 'invalid':\n",
    "            turn_record[\"result\"] = \"invalid action - turn skipped\"\n",
    "            self.turn_history.append(turn_record)\n",
    "            return\n",
    "        if action_type == 'place':\n",
    "            side, suit, price = params.get('side'), params.get('suit'), params.get('price')\n",
    "            book = self.order_books[(suit, side)]\n",
    "            new_order = Order(player.player_id, side, suit, price)\n",
    "            if side == 'bid':\n",
    "                opposing_book = self.order_books[(suit, 'offer')]\n",
    "                best_offer = opposing_book.get_best()\n",
    "                if best_offer and best_offer.price <= price and best_offer.player_id != player.player_id:\n",
    "                    self.execute_trade(buyer=player,\n",
    "                                       seller=self.players[best_offer.player_id],\n",
    "                                       suit=suit,\n",
    "                                       price=best_offer.price)\n",
    "                    turn_record[\"result\"] = \"trade executed on bid\"\n",
    "                    self.turn_history.append(turn_record)\n",
    "                    return\n",
    "            elif side == 'offer':\n",
    "                opposing_book = self.order_books[(suit, 'bid')]\n",
    "                best_bid = opposing_book.get_best()\n",
    "                if best_bid and best_bid.price >= price and best_bid.player_id != player.player_id:\n",
    "                    self.execute_trade(buyer=self.players[best_bid.player_id],\n",
    "                                       seller=player,\n",
    "                                       suit=suit,\n",
    "                                       price=best_bid.price)\n",
    "                    turn_record[\"result\"] = \"trade executed on offer\"\n",
    "                    self.turn_history.append(turn_record)\n",
    "                    return\n",
    "            if book.add_order(new_order):\n",
    "                player.active_orders.append(new_order)\n",
    "                turn_record[\"result\"] = \"order placed\"\n",
    "                self.pass_round = 1\n",
    "                for p in self.players:\n",
    "                    self.passed_in_round[p.player_id] = False\n",
    "            else:\n",
    "                turn_record[\"result\"] = \"order rejected unexpectedly\"\n",
    "        elif action_type == 'cancel':\n",
    "            side, suit, price = params.get('side'), params.get('suit'), params.get('price')\n",
    "            book = self.order_books[(suit, side)]\n",
    "            if book.cancel_order(player.player_id, price):\n",
    "                player.active_orders = [o for o in player.active_orders if not (o.side == side and o.suit == suit and o.price == price)]\n",
    "                turn_record[\"result\"] = \"order cancelled\"\n",
    "            else:\n",
    "                turn_record[\"result\"] = \"cancel failed unexpectedly\"\n",
    "        elif action_type == 'pass':\n",
    "            # Revised passing logic:\n",
    "            # Each round, record whether a player has passed.\n",
    "            if self.passed_in_round.get(player.player_id, False):\n",
    "                turn_record[\"result\"] = \"pass ineffective: already passed in current round\"\n",
    "            else:\n",
    "                self.passed_in_round[player.player_id] = True\n",
    "                player.pass_count += 1  # You can still increment for logging if desired.\n",
    "                turn_record[\"result\"] = f\"passed in round {self.pass_round}\"\n",
    "                # Check if all players have passed in this round.\n",
    "                if all(self.passed_in_round[p.player_id] for p in self.players):\n",
    "                    turn_record[\"result\"] += \" (complete round)\"\n",
    "                    self.pass_round += 1\n",
    "                    # Reset for next round.\n",
    "                    for p in self.players:\n",
    "                        self.passed_in_round[p.player_id] = False\n",
    "        else:\n",
    "            turn_record[\"result\"] = \"unknown action\"\n",
    "        self.turn_history.append(turn_record)\n",
    "\n",
    "    def execute_trade(self, buyer: Player, seller: Player, suit: str, price: int) -> None:\n",
    "        buyer.chips -= price\n",
    "        seller.chips += price\n",
    "        if seller.hand.get(suit, 0) > 0:\n",
    "            seller.hand[suit] -= 1\n",
    "            buyer.hand[suit] = buyer.hand.get(suit, 0) + 1\n",
    "        # else:\n",
    "            # print(f\"Error: {seller.name} does not have a {suit} card to trade.\")\n",
    "        event_time = datetime.now().isoformat()\n",
    "        trade_event = {\"turn\": self.turn_number, \"time\": event_time, \"buyer\": buyer.name, \"seller\": seller.name, \"suit\": suit, \"price\": price}\n",
    "        self.trade_history.append(trade_event)\n",
    "        self.clear_all_order_books()\n",
    "        for p in self.players:\n",
    "            p.active_orders.clear()\n",
    "\n",
    "        self.pass_round = 1\n",
    "        for p in self.players:\n",
    "            self.passed_in_round[p.player_id] = False\n",
    "        print(f\"Trade executed on turn {self.turn_number}: Buyer {buyer.name} bought {suit} from Seller {seller.name} for {price}\")\n",
    "\n",
    "    def get_public_state(self) -> dict:\n",
    "        state = {\n",
    "            \"players\": {},\n",
    "            \"order_books\": {},\n",
    "            \"trade_history\": self.trade_history,\n",
    "            \"turn_history\": self.turn_history,\n",
    "            \"game_over\": self.game_over,\n",
    "        }\n",
    "        for p in self.players:\n",
    "            net_delta = {s: p.hand.get(s, 0) - p.initial_hand.get(s, 0) for s in Game.SUITS}\n",
    "            state[\"players\"][p.name] = {\"chips\": p.chips, \"net_delta\": net_delta, \"pass_count\": p.pass_count, \"type\": p.player_type}\n",
    "        for (suit, side), book in self.order_books.items():\n",
    "            state[\"order_books\"][(suit, side)] = book.to_dict()\n",
    "        return state\n",
    "\n",
    "    def get_private_state(self) -> dict:\n",
    "        state = self.get_public_state()\n",
    "        state[\"full_hands\"] = {p.name: p.hand for p in self.players}\n",
    "        state[\"deck_config\"] = self.deck_config\n",
    "        state[\"common_suit\"] = self.common_suit\n",
    "        state[\"goal_suit\"] = self.goal_suit if self.game_over else None\n",
    "        return state\n",
    "\n",
    "    def select_next_player(self) -> Player:\n",
    "        valid_players = [p for p in self.players if p.player_id != self.last_player_id]\n",
    "        chosen = random.choice(valid_players)\n",
    "        self.last_player_id = chosen.player_id\n",
    "        return chosen\n",
    "\n",
    "    def run_turn(self):\n",
    "        if self.game_over:\n",
    "            return\n",
    "        player = self.select_next_player()\n",
    "        action = self.get_action(player)\n",
    "        self.process_action(player, action)\n",
    "        # Terminate game when two complete rounds have been done.\n",
    "        if self.pass_round > 2:\n",
    "            self.game_over = True\n",
    "\n",
    "    def run_game(self):\n",
    "        while not self.game_over:\n",
    "            self.run_turn()\n",
    "        # print(\"Game Over!\")\n",
    "        self.final_scoring()\n",
    "\n",
    "    def final_scoring(self) -> None:\n",
    "        # print(f\"Goal suit revealed: {self.goal_suit}\")\n",
    "        bonus_total = 0\n",
    "        for p in self.players:\n",
    "            bonus = 10 * p.hand.get(self.goal_suit, 0)\n",
    "            bonus_total += bonus\n",
    "            p.chips += bonus\n",
    "        remaining_pot = self.pot - bonus_total\n",
    "        if remaining_pot < 0:\n",
    "            remaining_pot = 0\n",
    "        goal_counts = {p.name: p.hand.get(self.goal_suit, 0) for p in self.players}\n",
    "        max_count = max(goal_counts.values())\n",
    "        winners = [name for name, count in goal_counts.items() if count == max_count]\n",
    "        if winners:\n",
    "            share = remaining_pot // len(winners)\n",
    "            for p in self.players:\n",
    "                if p.name in winners:\n",
    "                    p.chips += share\n",
    "        # print(\"Final chip counts:\")\n",
    "        # for p in self.players:\n",
    "        #     print(f\"{p.name}: {p.chips}\")\n",
    "\n",
    "    def export_game_log(self) -> dict:\n",
    "        log = {\n",
    "            \"game_id\": self.game_id,\n",
    "            \"round_number\": self.round_number,\n",
    "            \"end_time\": datetime.now().isoformat(),\n",
    "            \"host\": self.host,\n",
    "            \"settings\": self.settings,\n",
    "            \"human_players\": self.human_players,\n",
    "            \"bot_players\": self.bot_players,\n",
    "            \"goal_suit\": self.goal_suit if self.game_over else None,\n",
    "            \"starting_chips_and_hands\": self.starting_chips_and_hands,\n",
    "            \"game_updates\": self.turn_history,\n",
    "            \"final_chips_and_hands\": {p.name: {\"chips\": p.chips + self.ante, \"hand\": p.hand} for p in self.players}\n",
    "        }\n",
    "        return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd330c0-1cef-43b1-ada7-2eb654c964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def tokenize(s):\n",
    "    tokens = []\n",
    "    current = []\n",
    "    for char in s:\n",
    "        if char in ('(', ')'):\n",
    "            if current:\n",
    "                tokens.append(''.join(current))\n",
    "                current = []\n",
    "            tokens.append(char)\n",
    "        elif char.isspace():\n",
    "            if current:\n",
    "                tokens.append(''.join(current))\n",
    "                current = []\n",
    "        else:\n",
    "            current.append(char)\n",
    "    if current:\n",
    "        tokens.append(''.join(current))\n",
    "    return tokens\n",
    "\n",
    "def parse(tokens):\n",
    "    if not tokens:\n",
    "        return None\n",
    "    token = tokens.pop(0)\n",
    "    if token == '(':\n",
    "        lst = []\n",
    "        while tokens and tokens[0] != ')':\n",
    "            lst.append(parse(tokens))\n",
    "        if tokens:\n",
    "            tokens.pop(0)  # Remove the ')'\n",
    "        return lst\n",
    "    elif token == ')':\n",
    "        raise ValueError(\"Unexpected ')'\")\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "def parse_log(log_str):\n",
    "    tokens = tokenize(log_str)\n",
    "    parsed = parse(tokens)\n",
    "    data = {}\n",
    "    if isinstance(parsed, list):\n",
    "        for item in parsed:\n",
    "            if isinstance(item, list) and len(item) >= 2:\n",
    "                key = item[0]\n",
    "                value = item[1] if len(item) > 1 else None\n",
    "                data[key] = value\n",
    "    return data\n",
    "\n",
    "def parse_game_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    data = parse_log(content)\n",
    "\n",
    "    token_lines = []\n",
    "    has_bogus = False\n",
    "\n",
    "    # 1. Extract starting hands\n",
    "    starting_hands = data.get('starting_chips_and_hands', [])\n",
    "    for player_entry in starting_hands:\n",
    "        if isinstance(player_entry, list) and len(player_entry) >= 2:\n",
    "            player_name = player_entry[0]\n",
    "            player_data = player_entry[1]\n",
    "            hand_entries = []\n",
    "            chips = \"NA\"\n",
    "            for entry in player_data:\n",
    "                if isinstance(entry, list) and len(entry) >= 2:\n",
    "                    if entry[0] == 'chips':\n",
    "                        chips = entry[1]\n",
    "                    elif entry[0] == 'hand':\n",
    "                        # entry[1] should be list of suit entries\n",
    "                        suits = []\n",
    "                        for suit_entry in entry[1]:\n",
    "                            if isinstance(suit_entry, list) and len(suit_entry) >= 2:\n",
    "                                suit = suit_entry[0]\n",
    "                                count = suit_entry[1]\n",
    "                                suits.append(f\"{suit} {count}\")\n",
    "                        hand_entries = suits\n",
    "            # Format: \"playerName Chips <chips> <suit1> <count1> , <suit2> <count2> , ...\"\n",
    "            token_lines.append(f\"{player_name} Chips {chips} \" + \" , \".join(hand_entries) + \" <EOS>\")\n",
    "    \n",
    "    # 2. Process game_updates\n",
    "    game_updates = data.get('game_updates', [])\n",
    "    payouts = {}\n",
    "    for event in game_updates:\n",
    "        if isinstance(event, list) and len(event) >= 1:\n",
    "            event_type = event[0]\n",
    "            if event_type == 'Order':\n",
    "                order_info = {}\n",
    "                for item in event[1]:\n",
    "                    if isinstance(item, list) and len(item) >= 2:\n",
    "                        key = item[0]\n",
    "                        value = item[1]\n",
    "                        order_info[key] = value\n",
    "                # metadata is nested\n",
    "                meta = order_info.get('metadata', [])\n",
    "                meta_dict = {}\n",
    "                for m in meta:\n",
    "                    if isinstance(m, list) and len(m) >= 2:\n",
    "                        meta_dict[m[0]] = m[1]\n",
    "                user = meta_dict.get('user', '')\n",
    "                price = meta_dict.get('price', '')\n",
    "                if int(price) >= 60:\n",
    "                    has_bogus = True\n",
    "                suit = order_info.get('suit', '')\n",
    "                direction = order_info.get('direction', '')\n",
    "                token_lines.append(f\"Order {user} {price} {direction} {suit} <EOS>\")\n",
    "            elif event_type == 'Trade':\n",
    "                trade_info = {}\n",
    "                for item in event[1]:\n",
    "                    if isinstance(item, list) and len(item) >= 2:\n",
    "                        trade_info[item[0]] = item[1]\n",
    "                buyer = trade_info.get('buyer', '')\n",
    "                seller = trade_info.get('seller', '')\n",
    "                suit = trade_info.get('suit', '')\n",
    "                direction = trade_info.get('direction', '')\n",
    "                price = trade_info.get('price', '')\n",
    "                if direction == \"Buy\":\n",
    "                    token_lines.append(f\"Order {buyer} {price} {direction} {suit} <EOS>\")\n",
    "                else:\n",
    "                    token_lines.append(f\"Order {seller} {price} {direction} {suit} <EOS>\")\n",
    "                    \n",
    "            elif event_type == 'Payout':\n",
    "                payout_list = event[1] if len(event) >= 2 else []\n",
    "                for payout_entry in payout_list:\n",
    "                    if isinstance(payout_entry, list) and len(payout_entry) >= 2:\n",
    "                        player = payout_entry[0]\n",
    "                        amount = payout_entry[1]\n",
    "                        payouts[player] = amount\n",
    "            elif event_type == 'Goal':\n",
    "                # Goal event: e.g., (Goal Hearts)\n",
    "                goal = event[1] if len(event) > 1 else \"\"\n",
    "                token_lines.append(f\"Goal {goal} <EOS>\")\n",
    "    \n",
    "    # 3. Output payouts (if any)\n",
    "    if payouts:\n",
    "        for player, amount in payouts.items():\n",
    "            token_lines.append(f\"Payout {player} {amount} <EOS>\")\n",
    "    if has_bogus:\n",
    "        token_lines = None\n",
    "    return token_lines\n",
    "\n",
    "def create_token_dataset(folder_path: str) -> list:\n",
    "    global x\n",
    "    file_paths = glob.glob(os.path.join(folder_path, \"*\"))\n",
    "    dataset = []\n",
    "    for fp in file_paths:\n",
    "        token_seq = parse_game_file(fp)\n",
    "        if token_seq is not None:\n",
    "            y = 0\n",
    "            for tok in token_seq:\n",
    "                if \"Chips\" in tok:\n",
    "                    y += 1\n",
    "            if token_seq and y == 4:\n",
    "                # Join each event on a newline; each game becomes one block of text.\n",
    "                dataset.append(\"\\n\".join(token_seq) + '\\n------------------------')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "folder = \"data\"  # your data folder\n",
    "dataset = create_token_dataset(folder)\n",
    "print(f\"Processed {len(dataset)} games into token sequences.\\n\")\n",
    "\n",
    "# Optionally, save to a file:\n",
    "with open(\"figgie_full_game_token_dataset.txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    for seq in dataset:\n",
    "        fout.write(seq + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da47af-ec74-4543-95d7-90b88f30896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_order_book(events):\n",
    "    \"\"\"\n",
    "    Given a list of history events (as strings), compute a simple order book.\n",
    "    For each suit, track the best bid (highest price from Buy orders) and best offer (lowest price from Sell orders)\n",
    "    along with the respective player names.\n",
    "    Now, instead of clearing on a Trade event, we reset the order book for a suit\n",
    "    whenever the market gets \"crossed\" (i.e. best bid >= best offer).\n",
    "    \"\"\"\n",
    "    suits = [\"Hearts\", \"Diamonds\", \"Clubs\", \"Spades\"]\n",
    "    # For each suit, store bid as (price, player) and offer as (price, player)\n",
    "    order_book = {suit: {\"bid\": (None, None), \"offer\": (None, None)} for suit in suits}\n",
    "    \n",
    "    for event in events:\n",
    "        tokens = event.split()\n",
    "        # Process only Order events.\n",
    "        if tokens[0] == \"Order\" and len(tokens) >= 5:\n",
    "            user = tokens[1]\n",
    "            try:\n",
    "                price = int(tokens[2])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            direction = tokens[3]\n",
    "            suit = tokens[4]\n",
    "            if suit not in suits:\n",
    "                continue\n",
    "            \n",
    "            if direction == \"Buy\":\n",
    "                current_bid_price, _ = order_book[suit][\"bid\"]\n",
    "                # Update bid if no current bid or new price is higher.\n",
    "                if current_bid_price is None or price > current_bid_price:\n",
    "                    order_book[suit][\"bid\"] = (price, user)\n",
    "            elif direction == \"Sell\":\n",
    "                current_offer_price, _ = order_book[suit][\"offer\"]\n",
    "                # Update offer if no current offer or new price is lower.\n",
    "                if current_offer_price is None or price < current_offer_price:\n",
    "                    order_book[suit][\"offer\"] = (price, user)\n",
    "            \n",
    "            # After processing this order, check if the market is crossed for this suit.\n",
    "            bid_price, bid_user = order_book[suit][\"bid\"]\n",
    "            offer_price, offer_user = order_book[suit][\"offer\"]\n",
    "            if bid_price is not None and offer_price is not None and bid_price >= offer_price:\n",
    "                # Market is crossed: reset the order book for all suits.\n",
    "                for suit in suits:\n",
    "                    order_book[suit] = {\"bid\": (None, None), \"offer\": (None, None)}\n",
    "                # Optionally, record that a trade occurred if needed.\n",
    "    \n",
    "    # Build a string representation for the order book.\n",
    "    ob_parts = []\n",
    "    for suit in suits:\n",
    "        bid_price, bid_user = order_book[suit][\"bid\"]\n",
    "        offer_price, offer_user = order_book[suit][\"offer\"]\n",
    "        bid_str = f\"{bid_user} {bid_price}\" if bid_price is not None else \"\"\n",
    "        offer_str = f\"{offer_price} {offer_user}\" if offer_price is not None else \"\"\n",
    "        ob_parts.append(f\"{suit} {bid_str} @ {offer_str}\")\n",
    "    \n",
    "    order_book_str = \" \".join(ob_parts)\n",
    "    return order_book_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22188b33-ed5a-4ccd-a36b-4d42bc0c8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom preprocessing function\n",
    "def preprocess_game(file, include_order_book=False):\n",
    "    games = open(file).read().split('------------------------')\n",
    "    dataset = []\n",
    "\n",
    "    for game in games:\n",
    "        lines = game.strip().split('<EOS>')\n",
    "        player_hands = {}\n",
    "        history = []\n",
    "\n",
    "        # Extract initial hands\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            if line.startswith('apple') or line.startswith('banana') or line.startswith('cantaloupe') or line.startswith('durian'):\n",
    "                parts = line.split('Chips')\n",
    "                player, rest = parts[0].strip(), parts[1].strip()\n",
    "                idx = line.find(\"Clubs\")\n",
    "                new_rest = line[idx:]  # Get the substring starting with \"Clubs\"\n",
    "                player_hands[player] = new_rest.replace(', ', '')  # store player's initial hand line\n",
    "            elif line.startswith('Order') or line.startswith('Trade'):\n",
    "                history.append(line)\n",
    "\n",
    "        # Build sequences for each action prediction\n",
    "        for i, action in enumerate(history[:-1]):\n",
    "            next_action = history[i+1]\n",
    "            if next_action.startswith(\"Order\"):\n",
    "                acting_player = next_action.split()[1]\n",
    "            elif next_action.startswith(\"Trade\"):\n",
    "                parts = next_action.split()\n",
    "                player1, player2, action_type = parts[1], parts[2], parts[4]\n",
    "                acting_player = player1 if action_type == \"Buy\" else player2\n",
    "            else:\n",
    "                continue \n",
    "\n",
    "            if acting_player not in player_hands:\n",
    "                continue  # safety check\n",
    "        \n",
    "            if not include_order_book:\n",
    "                sequence = f\"<player> {acting_player} \" \\\n",
    "                           f\"<HAND> {player_hands[acting_player]} <HISTORY> \" \\\n",
    "                           + ' '.join(history[:i+1]) + \" <ACTION> \" + next_action + \" <|endoftext|>\"\n",
    "            else:\n",
    "                current_order_book = compute_order_book(history[:i + 1])\n",
    "                sequence = f\"<player> {acting_player} \" \\\n",
    "                           f\"<HAND> {player_hands[acting_player]} <HISTORY> \" \\\n",
    "                           + ' '.join(history[:i+1]) + f\" <ORDERBOOK> {current_order_book}\" + \" <ACTION> \" + next_action + \" [EOS]\"\n",
    "\n",
    "            dataset.append(sequence)\n",
    "\n",
    "    if not include_order_book:\n",
    "        with open('figgie_train.json', 'w') as f:\n",
    "            json.dump(dataset, f)\n",
    "    else:\n",
    "        with open('figgie_train_with_order_book.json', 'w') as f:\n",
    "            json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8dcf8-644e-4d6a-9409-60a9732a6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_game(\"figgie_full_game_token_dataset.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787f8d8-3ff2-4d45-add4-0e264a81a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('figgie_train_with_order_book.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480e35b-e928-4a37-8f26-b6aba5298538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "def create_dataset(include_order_book = False):\n",
    "    # Your allowed vocabulary (add all variations)\n",
    "    allowed_vocab = [\n",
    "        \"<player>\", \"<HAND>\", \"<HISTORY>\", \"<ACTION>\", \"<ORDERBOOK>\",\n",
    "        \"Spades\", \"Hearts\", \"Diamonds\", \"Clubs\",\n",
    "        \"Order\", \"Buy\", \"Sell\",\n",
    "        \"apple\", \"banana\", \"cantaloupe\", \"durian\",\n",
    "        \"Chips\", \"@\",\n",
    "        \"[UNK]\", \"[PAD]\", \"[EOS]\"  # Special tokens\n",
    "    ] + [str(i) for i in range(0, 60)]\n",
    "    \n",
    "    # Build a new vocabulary dictionary with contiguous IDs (0 to n-1)\n",
    "    new_vocab = {token: i for i, token in enumerate(allowed_vocab)}\n",
    "    \n",
    "    # Initialize a WordLevel model with the new vocabulary and an explicit unk_token.\n",
    "    tokenizer_model = models.WordLevel(vocab=new_vocab, unk_token=\"[UNK]\")\n",
    "    tokenizer = Tokenizer(tokenizer_model)\n",
    "    \n",
    "    # Set the pre-tokenizer to use whitespace splitting.\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "    \n",
    "    # Enable padding with the [PAD] token.\n",
    "    tokenizer.enable_padding(pad_token=\"[PAD]\")\n",
    "    \n",
    "    # Convert to a PreTrainedTokenizerFast for compatibility with Transformers.\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "    tokenizer.eos_token = \"[EOS]\"\n",
    "    tokenizer.pad_token = \"[PAD]\"\n",
    "    tokenizer.unk_token = \"[UNK]\"\n",
    "    print(tokenizer.vocab)\n",
    "    # Define dataset paths\n",
    "    if not include_order_book:\n",
    "        raw_dataset_path = 'figgie_train.json'\n",
    "        processed_dataset_path = 'figgie_tokenized_dataset'\n",
    "    else:\n",
    "        raw_dataset_path = 'figgie_train_with_order_book.json'\n",
    "        processed_dataset_path = 'figgie_tokenized_dataset_with_order_book'\n",
    "    \n",
    "    # Check if processed dataset already exists to avoid redundant work\n",
    "    if os.path.exists(processed_dataset_path):\n",
    "        print(\"Loading processed dataset from disk...\")\n",
    "        tokenized_datasets = load_from_disk(processed_dataset_path)\n",
    "    else:\n",
    "        # Load raw dataset\n",
    "        with open(raw_dataset_path) as f:\n",
    "            texts = json.load(f)\n",
    "    \n",
    "        # Split into train/eval (90% train, 10% eval)\n",
    "        split_idx = int(0.9 * len(texts))\n",
    "        train_texts = texts[:split_idx]\n",
    "        eval_texts = texts[split_idx:]\n",
    "        \n",
    "        datasets = DatasetDict({\n",
    "            \"train\": Dataset.from_dict({\"text\": texts[:split_idx]}),\n",
    "            \"eval\": Dataset.from_dict({\"text\": texts[split_idx:]})\n",
    "        })\n",
    "    \n",
    "        # Tokenization function\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=1024)\n",
    "    \n",
    "        # Tokenize dataset with parallelization and progress bar\n",
    "        tokenized_datasets = datasets.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            num_proc=4,\n",
    "            remove_columns=[\"text\"],\n",
    "            load_from_cache_file=True,\n",
    "            desc=\"Tokenizing dataset\"\n",
    "        )\n",
    "        \n",
    "        # Add labels for next-token prediction\n",
    "        def set_labels(examples):\n",
    "            examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "            return examples\n",
    "        \n",
    "        tokenized_datasets = tokenized_datasets.map(\n",
    "            set_labels, batched=False, num_proc=4, desc=\"Setting Labels\"\n",
    "        )\n",
    "    \n",
    "        # Save processed dataset to disk for easy reloading\n",
    "        tokenized_datasets.save_to_disk(processed_dataset_path)\n",
    "        print(\"Processed dataset saved to disk.\")\n",
    "    \n",
    "    print(\"Dataset ready to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a49c60-7a52-4980-8344-011dbae2ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(include_order_book = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2152d3-be97-4e93-a763-a9269c57b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_vocab = [\n",
    "    \"<player>\", \"<HAND>\", \"<HISTORY>\", \"<ACTION>\", \"<ORDERBOOK>\",\n",
    "    \"Spades\", \"Hearts\", \"Diamonds\", \"Clubs\",\n",
    "    \"Order\", \"Buy\", \"Sell\",\n",
    "    \"apple\", \"banana\", \"cantaloupe\", \"durian\",\n",
    "    \"Chips\", \"@\",\n",
    "    \"[UNK]\", \"[PAD]\", \"[EOS]\"  # Special tokens\n",
    "] + [str(i) for i in range(0, 60)]\n",
    "\n",
    "# Build a new vocabulary dictionary with contiguous IDs (0 to n-1)\n",
    "new_vocab = {token: i for i, token in enumerate(allowed_vocab)}\n",
    "\n",
    "# Initialize a WordLevel model with the new vocabulary and an explicit unk_token.\n",
    "tokenizer_model = models.WordLevel(vocab=new_vocab, unk_token=\"[UNK]\")\n",
    "tokenizer = Tokenizer(tokenizer_model)\n",
    "\n",
    "# Set the pre-tokenizer to use whitespace splitting.\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "\n",
    "# Enable padding with the [PAD] token.\n",
    "tokenizer.enable_padding(pad_token=\"[PAD]\")\n",
    "\n",
    "# Convert to a PreTrainedTokenizerFast for compatibility with Transformers.\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "tokenizer.eos_token = \"[EOS]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.unk_token = \"[UNK]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b7a8d-6d0e-4d5b-aa4c-5113189871ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = load_from_disk('figgie_tokenized_dataset_with_order_book')\n",
    "\n",
    "example = tokenized_datasets[\"train\"][0]  # get the first example\n",
    "decoded_text = tokenizer.decode(example[\"input_ids\"], skip_special_tokens=True)\n",
    "print(\"Decoded text (with special tokens):\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63b4a6-7afd-4d50-b86a-d943ba3b6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments, GPT2Config\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=len(tokenizer)\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model.to('cuda')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Data Collator for next-token prediction (MLM = False means causal LM)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False,\n",
    ")\n",
    "\n",
    "# Set up training arguments with evaluation enabled\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./figgie_final_new_tokenizer',\n",
    "    eval_strategy='steps',  # evaluate during training\n",
    "    eval_steps=3000,\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=10,\n",
    "    logging_dir='./logs',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_num_workers=4,\n",
    ")\n",
    "\n",
    "# Train using Trainer API\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b1bbb-81b2-44a1-872a-558c48ffeb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LogitsProcessor, LogitsProcessorList\n",
    "\n",
    "class CustomConstraintLogitsProcessor(LogitsProcessor):\n",
    "    \"\"\"\n",
    "    Custom logits processor to enforce that generated tokens follow the format:\n",
    "      <number (1-59)> <Buy|Sell> <Clubs|Diamonds|Hearts|Spades>\n",
    "    Requires setting the attribute prompt_length before generation.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        # Pre-compute allowed tokens for each position.\n",
    "        self.valid_numbers = [self.tokenizer.encode(str(i), add_special_tokens=False)[0]\n",
    "                              for i in range(1, 60)]\n",
    "        self.valid_sides = [self.tokenizer.encode(\"Buy\", add_special_tokens=False)[0],\n",
    "                            self.tokenizer.encode(\"Sell\", add_special_tokens=False)[0]]\n",
    "        self.valid_suits = [self.tokenizer.encode(suit, add_special_tokens=False)[0]\n",
    "                            for suit in [\"Clubs\", \"Diamonds\", \"Hearts\", \"Spades\"]]\n",
    "        self.prompt_length = None  # Will be set dynamically\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        if self.prompt_length is None:\n",
    "            raise ValueError(\"prompt_length must be set on CustomConstraintLogitsProcessor before generation.\")\n",
    "\n",
    "        # Determine how many new tokens have been generated:\n",
    "        new_tokens_generated = input_ids.shape[1] - self.prompt_length\n",
    "\n",
    "        # Only constrain the first three tokens (positions 0, 1, 2 of the new tokens)\n",
    "        if new_tokens_generated < 1:\n",
    "            valid = self.valid_numbers\n",
    "        elif new_tokens_generated == 1:\n",
    "            valid = self.valid_sides\n",
    "        elif new_tokens_generated == 2:\n",
    "            valid = self.valid_suits\n",
    "        else:\n",
    "            # No constraints for any extra tokens\n",
    "            return scores\n",
    "\n",
    "        # Create a mask: set scores for allowed tokens as-is, and everything else to -inf.\n",
    "        mask = torch.full_like(scores, float(\"-inf\"))\n",
    "        for token_id in valid:\n",
    "            mask[:, token_id] = scores[:, token_id]\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770e9cd-8262-4e9e-8fc0-f5b38899f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedPlayerWithOrderBook(Player):\n",
    "    def __init__(self, player_id, name, model, tokenizer, verbose=False, override_name=None):\n",
    "        super().__init__(player_id, name, player_type=\"bot\")\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_new_tokens = 3\n",
    "        self.last_prompt = \"\"\n",
    "        self.last_generated_action = \"\"\n",
    "        self.verbose = verbose\n",
    "        self.override_name = override_name\n",
    "\n",
    "    def build_prompt(self, player_hand, current_order_book, formatted_history):\n",
    "        # Define the fixed parts of the prompt.\n",
    "        fixed_prefix = f\"<player> {self.name} <HAND> {player_hand} <HISTORY> \"\n",
    "        fixed_suffix = f\" <ORDERBOOK> {current_order_book} <ACTION> Order {self.name}\"\n",
    "\n",
    "        # Start with no history.\n",
    "        current_history = \"\"\n",
    "        # Define dangerous limit (max tokens allowed for the full prompt).\n",
    "        dangerous_limit = 1024 - self.max_new_tokens # adjust as needed\n",
    "\n",
    "        # Build the prompt incrementally by prepending history events (most recent first)\n",
    "        # Note: we iterate in reverse so that the most recent events are considered first.\n",
    "        for event in reversed(formatted_history):\n",
    "            # Try adding the event at the beginning of the current history.\n",
    "            candidate_history = event + \" \" + current_history if current_history else event\n",
    "            candidate_prompt = fixed_prefix + candidate_history + fixed_suffix\n",
    "            token_ids = self.tokenizer.encode(candidate_prompt, add_special_tokens=False)\n",
    "            if len(token_ids) <= dangerous_limit:\n",
    "                current_history = candidate_history  # Accept the candidate history.\n",
    "            else:\n",
    "                # Stop if adding this event would exceed the dangerous limit.\n",
    "                break\n",
    "\n",
    "        # Build and return the final prompt.\n",
    "        final_prompt = fixed_prefix + current_history.strip() + fixed_suffix\n",
    "        return final_prompt\n",
    "\n",
    "    def swap_names(self, text, name1, name2):\n",
    "      tmp = \"__TMP__\"\n",
    "      return text.replace(name1, tmp).replace(name2, name1).replace(tmp, name2)\n",
    "\n",
    "    def decide_action(self, public_state: dict):\n",
    "        # Construct the player's starting hand\n",
    "        suit_order = [\"clubs\", \"diamonds\", \"hearts\", \"spades\"]\n",
    "\n",
    "        # Build the string by iterating over the suits in suit_order.\n",
    "        player_hand = \" \".join(f\"{suit.capitalize()} {self.initial_hand[suit]}\" for suit in suit_order if suit in self.initial_hand)\n",
    "        # Rebuild history in correct format\n",
    "        formatted_history = []\n",
    "        for turn in public_state[\"turn_history\"]:\n",
    "            action = turn[\"action\"]\n",
    "            params = turn[\"params\"]\n",
    "            player = turn[\"player\"]\n",
    "\n",
    "            if action == \"place\":\n",
    "                side = \"Buy\" if params[\"side\"] == \"bid\" else \"Sell\"\n",
    "                suit = params[\"suit\"].capitalize()\n",
    "                price = params[\"price\"]\n",
    "                formatted_history.append(f\"Order {player} {price} {side} {suit}\")\n",
    "            elif action == \"cancel\":\n",
    "                side = \"Buy\" if params[\"side\"] == \"bid\" else \"Sell\"\n",
    "                suit = params[\"suit\"].capitalize()\n",
    "                price = params[\"price\"]\n",
    "                formatted_history.append(f\"Cancel {player} {price} {side} {suit}\")\n",
    "            # elif action == \"pass\":\n",
    "            #     formatted_history.append(f\"Pass {player}\")\n",
    "            # Trades should already be formatted correctly in trade_history, but just in case:\n",
    "            elif action == \"trade\":\n",
    "                buyer = params[\"buyer\"]\n",
    "                seller = params[\"seller\"]\n",
    "                suit = params[\"suit\"].capitalize()\n",
    "                price = params[\"price\"]\n",
    "                formatted_history.append(f\"Trade {buyer} {seller} {suit} {price}\")\n",
    "\n",
    "        current_order_book = compute_order_book(formatted_history)\n",
    "\n",
    "        # Combine all parts into the final input string\n",
    "        # input_text1 = (\n",
    "        #     f\"<player> {self.name} \"\n",
    "        #     f\"<HAND> {player_hand} \"\n",
    "        #     f\"<HISTORY> {' '.join(formatted_history)} \"\n",
    "        #     f\"<ORDER BOOK> {current_order_book} \"\n",
    "        #     f\"<ACTION>\"\n",
    "        # )\n",
    "\n",
    "        input_text = self.build_prompt(player_hand, current_order_book, formatted_history)\n",
    "        if self.override_name is not None:\n",
    "          input_text = self.swap_names(input_text, \"apple\", self.override_name)\n",
    "        # print(input_text)\n",
    "        # if self.verbose:\n",
    "        #     print(tokenizer.tokenize(input_text))\n",
    "        # Tokenize and pass to model\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024-self.max_new_tokens).to('cuda')\n",
    "        self.last_prompt = inputs[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        # output = self.model.generate(\n",
    "        #     inputs[\"input_ids\"],\n",
    "        #     attention_mask=inputs[\"attention_mask\"],\n",
    "        #     min_new_tokens=self.max_new_tokens,\n",
    "        #     max_new_tokens=self.max_new_tokens,\n",
    "        #     do_sample=True,\n",
    "        #     temperature=0.8,\n",
    "        #     top_p=0.7,\n",
    "        #     early_stopping=False,\n",
    "        #     pad_token_id=self.tokenizer.eos_token_id,\n",
    "        # )\n",
    "        self.model.eval()\n",
    "        custom_processor = CustomConstraintLogitsProcessor(self.tokenizer)\n",
    "        custom_processor.prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "        logits_processor = LogitsProcessorList([custom_processor])\n",
    "        with torch.no_grad():\n",
    "          output = self.model.generate(\n",
    "              inputs[\"input_ids\"],\n",
    "              attention_mask=inputs[\"attention_mask\"],\n",
    "              logits_processor=logits_processor,\n",
    "              min_length=-1,\n",
    "              max_new_tokens=self.max_new_tokens,\n",
    "              do_sample=True,\n",
    "              temperature=0.8,\n",
    "              top_p=0.8,\n",
    "              # top_p=1.0,\n",
    "              # top_k=0.0,\n",
    "              early_stopping=False,\n",
    "              bad_words_ids=[tokenizer.encode('@', add_special_tokens=False)],\n",
    "              eos_token_id=tokenizer.eos_token_id,\n",
    "              pad_token_id=tokenizer.pad_token_id\n",
    "          )\n",
    "        self.last_generated_action = output[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "        token_ids = self.last_generated_action.tolist()\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        # if self.verbose:\n",
    "        #     print(tokens)\n",
    "        predicted_action = self.tokenizer.decode(self.last_generated_action, skip_special_tokens=False).strip()\n",
    "        if self.override_name is not None:\n",
    "            predicted_action = self.swap_names(predicted_action, \"apple\", self.override_name)\n",
    "        # Parse predicted action\n",
    "        return self.parse_action(predicted_action)\n",
    "\n",
    "    def parse_action(self, action_str):\n",
    "        try:\n",
    "            # if action_str.startswith(\"Order\"):\n",
    "            #     parts = action_str.split()\n",
    "            #     if len(parts) > 5:\n",
    "            #         parts = parts[:5]\n",
    "            #     if len(parts) == 5:\n",
    "            #         # print(action_str)\n",
    "            #         _, player, price, side, suit = parts\n",
    "            #         if player != self.name:\n",
    "            #             if self.verbose:\n",
    "            #                 print(\"Order predicted for another player, marking as invalid.\")\n",
    "            #             return ('invalid', {})\n",
    "            #         if price.isdigit():\n",
    "            #             price = int(price)\n",
    "            #         else:\n",
    "            #             if self.verbose:\n",
    "            #                 print(\"Malformed order action, marking as invalid.\")\n",
    "            #             return ('invalid', {})\n",
    "            #         if side.lower() != 'buy' and side.lower() != 'sell':\n",
    "            #             if self.verbose:\n",
    "            #                 print(\"Malformed order action, marking as invalid.\")\n",
    "            #             return ('invalid', {})\n",
    "            #         if suit.lower() not in Game.SUITS:\n",
    "            #             if self.verbose:\n",
    "            #                 print(\"Malformed order action, marking as invalid.\")\n",
    "            #             return ('invalid', {})\n",
    "            #         side = 'bid' if side.lower() == 'buy' else 'offer'\n",
    "            #         if self.verbose:\n",
    "            #             # print(action_str)\n",
    "            #             print('Order placed sucessfully')\n",
    "            #         return 'place', {'side': side, 'suit': suit.lower(), 'price': price}\n",
    "            #     else:\n",
    "            #         if self.verbose:\n",
    "            #             # print(action_str)\n",
    "            #             print(\"Malformed trade action, marking as invalid.\")\n",
    "            #         return ('invalid', {})\n",
    "            parts = action_str.split()\n",
    "            parts = [\"Order\", self.name, parts[0], parts[1], parts[2]]\n",
    "            if len(parts) > 5:\n",
    "                parts = parts[:5]\n",
    "            if len(parts) == 5:\n",
    "                # print(action_str)\n",
    "                _, player, price, side, suit = parts\n",
    "                if player != self.name:\n",
    "                    if self.verbose:\n",
    "                        print(\"Order predicted for another player, marking as invalid.\")\n",
    "                    return ('invalid', {})\n",
    "                if price.isdigit():\n",
    "                    price = int(price)\n",
    "                else:\n",
    "                    if self.verbose:\n",
    "                        print(action_str)\n",
    "                        print(\"Malformed order action, marking as invalid.\")\n",
    "                    return ('invalid', {})\n",
    "                if side.lower() != 'buy' and side.lower() != 'sell':\n",
    "                    if self.verbose:\n",
    "                        print(action_str)\n",
    "                        print(\"Malformed order action, marking as invalid.\")\n",
    "                    return ('invalid', {})\n",
    "                if suit.lower() not in Game.SUITS:\n",
    "                    if self.verbose:\n",
    "                        print(action_str)\n",
    "                        print(\"Malformed order action, marking as invalid.\")\n",
    "                    return ('invalid', {})\n",
    "                side = 'bid' if side.lower() == 'buy' else 'offer'\n",
    "                if self.verbose:\n",
    "                    print(action_str)\n",
    "                    print('Order placed sucessfully')\n",
    "                return 'place', {'side': side, 'suit': suit.lower(), 'price': price}\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(action_str)\n",
    "                    print(\"Malformed trade action, marking as invalid.\")\n",
    "                return ('invalid', {})\n",
    "\n",
    "            # elif action_str.startswith(\"Trade\"):\n",
    "            #     parts = action_str.split()\n",
    "            #     if len(parts) > 6:\n",
    "            #         parts = parts[:6]\n",
    "            #     if len(parts) == 6:\n",
    "            #         _, buyer, seller, suit, side, price = parts\n",
    "            #         side = 'bid' if side.lower() == 'buy' else 'offer'\n",
    "            #         acting_player = buyer if side == 'bid' else seller\n",
    "            #         if acting_player != self.name:\n",
    "            #             print(\"Trade predicted for another player, marking as invalid.\")\n",
    "            #             return ('invalid', {})\n",
    "            #         return 'place', {'side': side, 'suit': suit.lower(), 'price': int(price)}\n",
    "            #     else:\n",
    "            #         print(action)\n",
    "            #         print(\"Malformed trade action, marking as invalid.\")\n",
    "            #         return ('invalid', {})\n",
    "            # elif action_str.startswith(\"Cancel\"):\n",
    "            #     parts = action_str.split()\n",
    "            #     if len(parts) == 5:\n",
    "            #         print(\"A PLAYER HAS CANCELLED\")\n",
    "            #         _, player, price, side, suit = parts\n",
    "            #         side = 'bid' if side.lower() == 'buy' else 'offer'\n",
    "            #         return 'cancel', {'side': side, 'suit': suit.lower(), 'price': int(price)}\n",
    "            #     else:\n",
    "            #         print(\"Malformed cancel action, marking as invalid.\")\n",
    "            #         return ('invalid', {})\n",
    "            # elif action_str.startswith(\"Pass\"):\n",
    "            #     print('A PLAYER HAS PASSED')\n",
    "            #     return ('pass', {})\n",
    "            # else:\n",
    "            #     if self.verbose:\n",
    "            #         # print(action_str)\n",
    "            #         print(\"Unrecognized action, marking as invalid.\")\n",
    "            #     return ('invalid', {})\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"Error parsing action: {e}. Marking as invalid.\")\n",
    "            return ('invalid', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da25c46-4907-4c16-8402-b1ffa8b51a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"apple\", \"banana\", \"cantaloupe\", \"durian\"]\n",
    "players = []\n",
    "for i in range(4):\n",
    "    if i == 0:\n",
    "        # RL player uses the trainable model.\n",
    "        players.append(SupervisedPlayerWithOrderBook(i, names[i], model, tokenizer, verbose=False))\n",
    "    else:\n",
    "        # Static players use the fixed reference model.\n",
    "        players.append(SupervisedPlayerWithOrderBook(i, names[i], model_ref, tokenizer, verbose=False))\n",
    "game = Game(num_players=4, players=players)\n",
    "game.run_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1b509-417e-4865-b337-b3d4f197cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reward(game, action_str, turn, goal_suit, starting_chips=350):\n",
    "    result = turn.get(\"result\", \"\").lower()\n",
    "    if \"invalid action - turn skipped\" in result:\n",
    "        print(action_str)\n",
    "        print(\"PUNISHED\")\n",
    "        return -3.0  # Penalize invalid/ skipped actions immediately.\n",
    "\n",
    "    parts = action_str.split()\n",
    "    price = int(parts[0])\n",
    "    action_type = parts[1].lower()\n",
    "    suit = parts[2].lower()\n",
    "\n",
    "    # (1) Chip reward: Use final chip difference, but with a low weight.\n",
    "    public_state = game.get_public_state()\n",
    "    player_name = turn[\"player\"]\n",
    "    trade_reward = 0.0\n",
    "    trade_executed = \"trade executed\" in result  # Check whether a trade actually occurred.\n",
    "    order_placed = \"order placed\" in result\n",
    "    if (not trade_executed) and (not order_placed):\n",
    "        # we just return a reward of 0 for passing\n",
    "        return 0\n",
    "    if suit != goal_suit.lower():\n",
    "        # For non-goal suits, simply use the price.\n",
    "        if action_type == \"buy\":\n",
    "            trade_reward = -price\n",
    "        elif action_type == \"sell\":\n",
    "            trade_reward = price\n",
    "    else:\n",
    "        # For goal suits, use a marginal value table.\n",
    "        marginal_values = [10, 11, 13, 20, 50]  # Values for transitions: 0->1, 1->2, ..., 4->5.\n",
    "        # Get the current count for the goal suit from the player's private state.\n",
    "        private_state = game.get_private_state()\n",
    "        hand = private_state[\"full_hands\"][player_name].get(\"hand\", {})  # e.g., {'clubs': 3, 'hearts': 5, ...}\n",
    "        count_before = hand.get(suit, 0) - 1 if trade_executed else hand.get(suit, 0)\n",
    "        if action_type == \"buy\":\n",
    "            if count_before >= 5:\n",
    "                # If already at or above optimal, further buys are penalized.\n",
    "                trade_reward = 10 - price\n",
    "            else:\n",
    "                # Reward is the marginal benefit minus the cost.\n",
    "                trade_reward = marginal_values[count_before] - price\n",
    "        elif action_type == \"sell\":\n",
    "            if count_before > 5:\n",
    "                trade_reward = price - 10\n",
    "            else:\n",
    "                trade_reward = price - marginal_values[count_before - 1]\n",
    "\n",
    "    return trade_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f575d-0e82-4865-a601-97e542da91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import PPOConfig, PPOTrainer, AutoModelForCausalLMWithValueHead\n",
    "from tqdm import tqdm\n",
    "\n",
    "ppo_config_dict = {\n",
    "    \"batch_size\": 16,             # Keep it small if data per update is limited.\n",
    "    \"mini_batch_size\": 8,\n",
    "    \"learning_rate\": 1e-5,        # Lower learning rate to ensure smoother updates.\n",
    "    \"init_kl_coef\": 0.5,          # Increase KL coefficient to penalize divergence more.\n",
    "    \"target_kl\": 0.5,             # Lower target KL threshold for tighter policy updates.\n",
    "    \"cliprange\": 0.1,             # Lower clip range to limit aggressive policy updates.\n",
    "    \"max_grad_norm\": 1.0,         # Add gradient clipping for additional stability.\n",
    "}\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"checkpoint-4000-new-tokenizer\").to('cuda')\n",
    "# Load the reference model (a separate copy) for PPO. This model stays fixed during the update.\n",
    "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\"checkpoint-4000-new-tokenizer\").to('cuda')\n",
    "model_ref.eval()\n",
    "config = PPOConfig(**ppo_config_dict)\n",
    "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)\n",
    "\n",
    "games_per_update = 10  # Run 10 games before each PPO update.\n",
    "num_blocks = 200       # For example, 200 blocks * 10 games = 2000 games total.\n",
    "\n",
    "# Initialize lists to accumulate trajectories across games.\n",
    "all_queries = []\n",
    "all_responses = []\n",
    "all_rewards = []\n",
    "all_stats = []\n",
    "\n",
    "for block in tqdm(range(num_blocks)):\n",
    "    for game_idx in tqdm(range(games_per_update)):\n",
    "        names = [\"apple\", \"banana\", \"cantaloupe\", \"durian\"]\n",
    "        players = []\n",
    "        for i in range(4):\n",
    "            if i == 0:\n",
    "                # RL player uses the trainable model.\n",
    "                players.append(SupervisedPlayerWithOrderBook(i, names[i], model, tokenizer, verbose=False))\n",
    "            else:\n",
    "                # Static players use the fixed reference model.\n",
    "                players.append(SupervisedPlayerWithOrderBook(i, names[i], model_ref, tokenizer, verbose=False))\n",
    "        game = Game(num_players=4, players=players)\n",
    "        model.eval()\n",
    "        game.run_game()\n",
    "\n",
    "        # --- Collect trajectories for the RL player (names[0]) ---\n",
    "        with torch.no_grad():\n",
    "          public_state = game.get_public_state()\n",
    "          for turn in game.turn_history:\n",
    "              if turn[\"player\"] != names[0]:\n",
    "                  continue\n",
    "              prompt = turn.get(\"prompt\", \"\")\n",
    "              action = turn.get(\"last_generated_action\", \"\")\n",
    "              reward = compute_reward(game, tokenizer.decode(action), turn, game.goal_suit)\n",
    "              all_queries.append(prompt)\n",
    "              all_responses.append(action)\n",
    "              all_rewards.append(torch.tensor(reward, device='cuda', dtype=torch.float))\n",
    "\n",
    "    # --- Perform PPO update after accumulating trajectories from 10 games ---\n",
    "    if len(all_queries) > 0:\n",
    "        print(f\"Updating model after block {block+1} with {len(all_queries)} examples...\")\n",
    "        model.train()\n",
    "        batch_size = 16\n",
    "        num_examples = len(all_queries)\n",
    "        for i in range(0, num_examples, batch_size):\n",
    "            queries_batch = all_queries[i:i+batch_size]\n",
    "            responses_batch = all_responses[i:i+batch_size]\n",
    "            rewards_batch = all_rewards[i:i+batch_size]\n",
    "            # Update only on full batches; adjust as needed for partial batches.\n",
    "            if len(queries_batch) == batch_size:\n",
    "                stats = ppo_trainer.step(queries_batch, responses_batch, rewards_batch)\n",
    "                all_stats.append(stats)\n",
    "        # Clear the accumulated trajectories after PPO updates.\n",
    "        all_queries = []\n",
    "        all_responses = []\n",
    "        all_rewards = []\n",
    "\n",
    "    if (block + 1) % 10 == 0:\n",
    "        # Save a checkpoint after each block.\n",
    "        model.save_pretrained(f\"rl_test_model2{block+1}\")\n",
    "        tokenizer.save_pretrained(f\"rl_test_model2{block+1}\")\n",
    "        print(f\"Saved checkpoint for block {block+1}\")\n",
    "\n",
    "model.save_pretrained(\"rl_test_model2\")\n",
    "tokenizer.save_pretrained(\"rl_test_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac83700-8a07-42b1-a26e-ac9c98238824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from typing import Optional, Tuple, Union, Dict, Any\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomPPOModelWithAux(AutoModelForCausalLMWithValueHead):\n",
    "    \"\"\"\n",
    "    Custom PPO model with an auxiliary head for predicting the goal suit in Figgie game.\n",
    "    Inherits from AutoModelForCausalLMWithValueHead and adds an auxiliary classification head.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model,\n",
    "        num_suits: int = 4,  # Number of possible suits to predict\n",
    "        value_head_dropout: float = 0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Initialize the parent class (PPO model with value head)\n",
    "        super().__init__(pretrained_model, **kwargs)\n",
    "        self.current_aux_labels = None\n",
    "        self.aux_logits = None\n",
    "\n",
    "        # Copy all attributes from the parent class that might be needed\n",
    "        self.is_peft_model = getattr(pretrained_model, \"is_peft_model\", False)\n",
    "\n",
    "        # Get the hidden size from the pretrained model config\n",
    "        hidden_size = self.pretrained_model.config.hidden_size\n",
    "\n",
    "        # Add an auxiliary classification head for suit prediction\n",
    "        self.aux_head_goal = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(value_head_dropout),\n",
    "            nn.Linear(hidden_size, num_suits)\n",
    "        )\n",
    "        # Auxiliary head for final chip counts (4 players)\n",
    "        self.aux_head_chip = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(value_head_dropout),\n",
    "            nn.Linear(hidden_size, 4),\n",
    "            nn.ReLU()  # optionally ensure non-negative outputs\n",
    "        )\n",
    "        # Auxiliary head for hand composition (16 outputs)\n",
    "        self.aux_head_hand = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(value_head_dropout),\n",
    "            nn.Linear(hidden_size, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Auxiliary head for trade prediction (binary classification)\n",
    "        self.aux_head_trade = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(value_head_dropout),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "        # Initialize weights for all auxiliary heads\n",
    "        for head in [self.aux_head_goal, self.aux_head_chip, self.aux_head_hand, self.aux_head_trade]:\n",
    "            for module in head:\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                    if module.bias is not None:\n",
    "                        module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward pass with integrated auxiliary loss calculation.\n",
    "        Handles both base model outputs and custom auxiliary task.\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Get base model outputs with hidden states\n",
    "        base_outputs = self.pretrained_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,  # Required for auxiliary task\n",
    "            return_dict=True,            # Get structured outputs\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        lm_logits = base_outputs.logits\n",
    "        loss = base_outputs.loss\n",
    "        hidden_states = base_outputs.hidden_states[-1] # (B, T, hidden_size)\n",
    "\n",
    "        value = self.v_head(hidden_states).squeeze(-1) # Now value has shape (B, T)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            seq_lens = (attention_mask.sum(dim=1) - 1).long()\n",
    "        else:\n",
    "            seq_lens = torch.tensor([input_ids.shape[1]-1]*input_ids.shape[0], device=input_ids.device, dtype=torch.long)\n",
    "\n",
    "        last_hidden = hidden_states[torch.arange(hidden_states.size(0)), seq_lens]\n",
    "\n",
    "        if self.current_aux_labels is not None:\n",
    "            # Example dict: {\n",
    "            #   \"goal\": tensor([...], dtype=torch.long),\n",
    "            #   \"chip\": tensor([...], dtype=torch.float or long),\n",
    "            #   \"hand\": tensor([...], dtype=torch.float or long),\n",
    "            #   \"trade\": tensor([...], dtype=torch.float)  # binary 0 or 1\n",
    "            # }\n",
    "            current_batch_size = input_ids.shape[0]\n",
    "\n",
    "            # Unpack auxiliary targets (and ensure proper device placement)\n",
    "            goal_labels = self.current_aux_labels[\"goal\"][:current_batch_size].to(input_ids.device)\n",
    "            chip_labels = self.current_aux_labels[\"chip\"][:current_batch_size].to(input_ids.device)\n",
    "            hand_labels = self.current_aux_labels[\"hand\"][:current_batch_size].to(input_ids.device)\n",
    "            trade_labels = self.current_aux_labels[\"trade\"][:current_batch_size].to(input_ids.device)\n",
    "\n",
    "            # Compute predictions from each head\n",
    "            aux_logits_goal = self.aux_head_goal(last_hidden)\n",
    "            aux_logits_chip = self.aux_head_chip(last_hidden)\n",
    "            aux_logits_hand = self.aux_head_hand(last_hidden)\n",
    "            aux_logits_trade = self.aux_head_trade(last_hidden)\n",
    "\n",
    "            self.aux_logits = {\n",
    "                \"goal\": aux_logits_goal,\n",
    "                \"chip\": aux_logits_chip,\n",
    "                \"hand\": aux_logits_hand,\n",
    "                \"trade\": aux_logits_trade\n",
    "            }\n",
    "\n",
    "            # Losses:\n",
    "            loss_goal = F.cross_entropy(aux_logits_goal, goal_labels.long()) / 1.5\n",
    "            loss_chip = F.mse_loss(aux_logits_chip, chip_labels.float()) / 127000\n",
    "            loss_hand = F.mse_loss(aux_logits_hand, hand_labels.float()) / 10\n",
    "            loss_trade = F.binary_cross_entropy_with_logits(aux_logits_trade.squeeze(-1), trade_labels.float()) / 0.75\n",
    "\n",
    "            # Weights for each auxiliary loss (starting values; tune as needed)\n",
    "            w_goal, w_chip, w_hand, w_trade = .35, .20, .30, .15\n",
    "\n",
    "            aux_loss = w_goal * loss_goal + w_chip * loss_chip + w_hand * loss_hand + w_trade * loss_trade\n",
    "            # print(f\"main loss: {loss}\")\n",
    "            # print(f\"goal loss: {loss_goal}\")\n",
    "            # print(f\"chip loss: {loss_chip}\")\n",
    "            # print(f\"hand loss: {loss_hand}\")\n",
    "            # print(f\"trade loss: {loss_trade}\")\n",
    "            loss = (loss if loss is not None else 0) + aux_loss\n",
    "\n",
    "        return (lm_logits, loss, value)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n",
    "        \"\"\"\n",
    "        Load a pretrained model and add auxiliary and value heads.\n",
    "        \"\"\"\n",
    "        # Extract kwargs specific to our class\n",
    "        num_suits = kwargs.pop('num_suits', 4) if 'num_suits' in kwargs else 4\n",
    "        custom_kwargs = {'num_suits': num_suits}\n",
    "\n",
    "        # Load using the parent class from_pretrained to handle value head properly\n",
    "        base_model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "            pretrained_model_name_or_path, *model_args, **kwargs\n",
    "        )\n",
    "\n",
    "        # Create our model using the base model's pretrained part\n",
    "        model = cls(base_model.pretrained_model, **custom_kwargs)\n",
    "\n",
    "        # Copy the value head weights from the loaded model\n",
    "        model.v_head.load_state_dict(base_model.v_head.state_dict())\n",
    "\n",
    "        return model\n",
    "\n",
    "    def save_pretrained(self, save_directory, **kwargs):\n",
    "        \"\"\"\n",
    "        Save the model to the specified directory.\n",
    "        \"\"\"\n",
    "        # Save the base pretrained model using the parent class method\n",
    "        super().save_pretrained(save_directory, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae387e6-e9e0-42b7-8ad2-9fd98f364eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from trl import PPOConfig, PPOTrainer, AutoModelForCausalLMWithValueHead\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_path = \"checkpoint-4000-new-tokenizer\"\n",
    "names = [\"apple\", \"banana\", \"cantaloupe\", \"durian\"]\n",
    "suit_to_idx = {\"spades\": 0, \"hearts\": 1, \"diamonds\": 2, \"clubs\": 3}\n",
    "\n",
    "ppo_config_dict = {\n",
    "    \"batch_size\": 16,             # Keep it small if data per update is limited.\n",
    "    \"mini_batch_size\": 8,\n",
    "    \"learning_rate\": 1e-5,        # Lower learning rate to ensure smoother updates.\n",
    "    \"init_kl_coef\": 0.5,          # Increase KL coefficient to penalize divergence more.\n",
    "    \"target_kl\": 0.5,             # Lower target KL threshold for tighter policy updates.\n",
    "    \"cliprange\": 0.1,             # Lower clip range to limit aggressive policy updates.\n",
    "    \"max_grad_norm\": 1.0,         # Add gradient clipping for additional stability.\n",
    "}\n",
    "\n",
    "# ---- Initialize Models ----\n",
    "model = CustomPPOModelWithAux.from_pretrained(model_path, num_suits=4).to('cuda')\n",
    "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(model_path).to('cuda').eval()\n",
    "\n",
    "# ---- Training Setup ----\n",
    "config = PPOConfig(**ppo_config_dict)\n",
    "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)\n",
    "\n",
    "# --- Training Loop ---\n",
    "games_per_update = 10\n",
    "num_blocks = 200\n",
    "batch_size = config.batch_size\n",
    "\n",
    "for block in tqdm(range(1, num_blocks + 1), desc=\"Training Blocks\"):\n",
    "    queries_text, queries, responses, rewards = [], [], [], []\n",
    "    aux_labels = []\n",
    "\n",
    "    # ---- Game Simulation ----\n",
    "    for game_idx in tqdm(range(games_per_update), leave=False, desc=\"Games\"):\n",
    "        players = [\n",
    "            SupervisedPlayerWithOrderBook(0, names[0], model, tokenizer, verbose=False), # RL player uses the trainable model.\n",
    "            SupervisedPlayerWithOrderBook(1, names[1], model_ref, tokenizer, verbose=False),\n",
    "            SupervisedPlayerWithOrderBook(2, names[2], model_ref, tokenizer, verbose=False),\n",
    "            SupervisedPlayerWithOrderBook(3, names[3], model_ref, tokenizer, verbose=False),\n",
    "        ]\n",
    "\n",
    "        game = Game(num_players=4, players=players)\n",
    "        game.run_game()\n",
    "        goal_suit_idx = suit_to_idx[game.goal_suit.lower()]\n",
    "        game_log_final_chips_and_hand = game.export_game_log()[\"final_chips_and_hands\"]\n",
    "\n",
    "        # ---- Collect Trajectories ----\n",
    "        with torch.no_grad():\n",
    "            for turn in filter(lambda t: t[\"player\"] == names[0], game.turn_history):\n",
    "                prompt_tokens = turn.get(\"prompt\", torch.tensor([], device=\"cuda\"))\n",
    "                prompt = tokenizer.decode(prompt_tokens, skip_special_tokens=True)\n",
    "\n",
    "                action = turn.get(\"last_generated_action\", torch.tensor([]))\n",
    "                decoded_action = tokenizer.decode(action, skip_special_tokens=True)\n",
    "\n",
    "                # Calculate reward\n",
    "                reward_val = compute_reward(game, decoded_action, turn, game.goal_suit)\n",
    "\n",
    "                # Collect auxiliary targets:\n",
    "                chip_counts = [players[i].chips for i in range(4)]\n",
    "                hand_vector = []\n",
    "                for name in names:\n",
    "                    hand = game.get_private_state()[\"full_hands\"][name]\n",
    "                    hand_vector.extend([hand.get(\"clubs\", 0), hand.get(\"diamonds\", 0),\n",
    "                                        hand.get(\"hearts\", 0), hand.get(\"spades\", 0)])\n",
    "                trade_flag = 1 if \"trade executed\" in turn.get(\"result\", \"\").lower() else 0\n",
    "\n",
    "                # Store training data\n",
    "                queries.append(prompt_tokens)\n",
    "                queries_text.append(prompt)\n",
    "                responses.append(action)\n",
    "                rewards.append(torch.tensor(reward_val, device=\"cuda\", dtype=torch.float))\n",
    "                aux_labels.append({\n",
    "                    \"goal\": goal_suit_idx,\n",
    "                    \"chip\": chip_counts,\n",
    "                    \"hand\": hand_vector,\n",
    "                    \"trade\": trade_flag\n",
    "                })\n",
    "\n",
    "    # ---- PPO + Auxiliary Updates ----\n",
    "    if queries:\n",
    "        total_samples = len(queries)\n",
    "        if total_samples % batch_size != 0:\n",
    "            pad_needed = batch_size - (total_samples % batch_size)\n",
    "\n",
    "            queries += [queries[-1]] * pad_needed\n",
    "            queries_text += [queries_text[-1]] * pad_needed\n",
    "            responses += [responses[-1]] * pad_needed\n",
    "            rewards += [rewards[-1]] * pad_needed\n",
    "            aux_labels += [aux_labels[-1]] * pad_needed\n",
    "\n",
    "        print(f\"[Block {block}] Training with {len(queries)} samples...\")\n",
    "        model.train()\n",
    "\n",
    "        for i in range(0, len(queries), batch_size):\n",
    "            batch_queries = queries[i:i+batch_size]\n",
    "            batch_queries_text = queries_text[i:i+batch_size]\n",
    "            batch_responses = responses[i:i+batch_size]\n",
    "            batch_rewards = rewards[i:i+batch_size]\n",
    "            batch_aux_labels = aux_labels[i:i+batch_size]\n",
    "\n",
    "            # Collate auxiliary targets into tensors\n",
    "            goal_targets = torch.tensor([a['goal'] for a in batch_aux_labels], dtype=torch.long, device=\"cuda\")\n",
    "            chip_targets = torch.tensor([a['chip'] for a in batch_aux_labels], dtype=torch.float, device=\"cuda\")\n",
    "            hand_targets = torch.tensor([a['hand'] for a in batch_aux_labels], dtype=torch.float, device=\"cuda\")\n",
    "            trade_targets = torch.tensor([a['trade'] for a in batch_aux_labels], dtype=torch.float, device=\"cuda\")\n",
    "\n",
    "            model.current_aux_labels = {\n",
    "                \"goal\": goal_targets,\n",
    "                \"chip\": chip_targets,\n",
    "                \"hand\": hand_targets,\n",
    "                \"trade\": trade_targets,\n",
    "            }\n",
    "\n",
    "            # ---- PPO Step ----\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                ppo_stats = ppo_trainer.step(\n",
    "                    batch_queries,\n",
    "                    batch_responses,\n",
    "                    batch_rewards,\n",
    "                )\n",
    "            print(ppo_stats)\n",
    "\n",
    "            # Clear temporary storage\n",
    "            model.current_aux_labels = None\n",
    "\n",
    "            # Memory cleanup\n",
    "            del batch_rewards, batch_aux_labels\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        queries.clear()\n",
    "        responses.clear()\n",
    "        rewards.clear()\n",
    "        queries_text.clear()\n",
    "        aux_labels.clear()\n",
    "\n",
    "    # --- Checkpoint ---\n",
    "    if block % 10 == 0:\n",
    "        ckpt_path = f\"aux_model_{block}\"\n",
    "        model.save_pretrained(ckpt_path)\n",
    "        model = model.to('cuda')\n",
    "        tokenizer.save_pretrained(ckpt_path)\n",
    "        print(f\"[Checkpoint] Saved model at block {block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5efb7-4cbf-4db8-9b99-18b13b608d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from tqdm import tqdm\n",
    "lengths = []\n",
    "chip_vals = []\n",
    "winners = []\n",
    "logs = []\n",
    "# rl_model_path = \"/content/drive/MyDrive/checkpoint-4000-new-tokenizer\"\n",
    "rl_model_path = \"rl_test_model2\"\n",
    "rl_model = AutoModelForCausalLMWithValueHead.from_pretrained(rl_model_path).to(\"cuda\")\n",
    "\n",
    "# Load the static model (for the other three players) from the usual checkpoint.\n",
    "static_model_path = \"checkpoint-4000-new-tokenizer\"\n",
    "static_model = AutoModelForCausalLMWithValueHead.from_pretrained(static_model_path).to(\"cuda\")\n",
    "# Here we assume the tokenizer is the same (or similar) for both.\n",
    "# If needed, you could also load a separate tokenizer:\n",
    "# static_tokenizer = PreTrainedTokenizerFast.from_pretrained(static_model_path)\n",
    "# For this example, we will use the RL tokenizer for all players.\n",
    "\n",
    "# -------------------------------\n",
    "# Set Up Players and Tournament\n",
    "# -------------------------------\n",
    "\n",
    "# Assuming player names are defined as follows:\n",
    "names = [\"apple\", \"banana\", \"cantaloupe\", \"durian\"]\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Run Tournament and Collect Stats\n",
    "# -------------------------------\n",
    "\n",
    "num_games = 1000\n",
    "# Dictionary to accumulate total chips for each player over all games.\n",
    "total_chip_counts = {name: 0 for name in names}\n",
    "\n",
    "for game_num in tqdm(range(num_games)):\n",
    "    # Create players.\n",
    "    # Player 0 will be the RL (trainable) player,\n",
    "    # and players 1-3 will be static (using the fixed model).\n",
    "    players = []\n",
    "    players.append(SupervisedPlayerWithOrderBook(0, names[0], rl_model, tokenizer, verbose=False))\n",
    "    for i in range(1, 4):\n",
    "        players.append(SupervisedPlayerWithOrderBook(i, names[i], static_model, tokenizer, verbose=False, override_name=names[i]))\n",
    "    # Create a new game instance with a fresh state.\n",
    "    game = Game(num_players=4, players=players)\n",
    "    game.run_game()  # This runs the game simulation.\n",
    "    logs.append(game.export_game_log())\n",
    "    # Retrieve the final public state of the game.\n",
    "    # We assume `get_public_state()` returns a dict with a \"players\" key,\n",
    "    # where each entry is like: {\"chips\": <chip_count>, ...}.\n",
    "    public_state = game.get_public_state()\n",
    "\n",
    "    print(f\"\\nGame {game_num + 1} final chip values:\")\n",
    "    for i in range(4):\n",
    "        chips = players[i].chips\n",
    "        print(f\"{names[i]}: {chips}\")\n",
    "        total_chip_counts[names[i]] += chips\n",
    "    winners.append(game.goal_suit_winner)\n",
    "    lengths.append(len(game.turn_history))\n",
    "    chip_vals.append([players[0].chips, players[1].chips, players[2].chips, players[3].chips])\n",
    "\n",
    "# Calculate and print average chip counts over all games.\n",
    "print(\"\\nAverage chip values over {} games:\".format(num_games))\n",
    "for name in names:\n",
    "    avg_chips = total_chip_counts[name] / num_games\n",
    "    print(f\"{name}: {avg_chips}\")\n",
    "\n",
    "print(lengths)\n",
    "print(chip_vals)\n",
    "print(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f46566-4c92-45c4-bec7-4ba76f7e83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from tqdm import tqdm\n",
    "lengths = []\n",
    "chip_vals = []\n",
    "winners = []\n",
    "logs = []\n",
    "# rl_model_path = \"/content/drive/MyDrive/checkpoint-4000-new-tokenizer\"\n",
    "rl_model_path = \"aux_block_200\"\n",
    "rl_model = AutoModelForCausalLMWithValueHead.from_pretrained(rl_model_path).to(\"cuda\")\n",
    "\n",
    "# Load the static model (for the other three players) from the usual checkpoint.\n",
    "static_model_path = \"checkpoint-4000-new-tokenizer\"\n",
    "static_model = AutoModelForCausalLMWithValueHead.from_pretrained(static_model_path).to(\"cuda\")\n",
    "# Here we assume the tokenizer is the same (or similar) for both.\n",
    "# If needed, you could also load a separate tokenizer:\n",
    "# static_tokenizer = PreTrainedTokenizerFast.from_pretrained(static_model_path)\n",
    "# For this example, we will use the RL tokenizer for all players.\n",
    "\n",
    "# -------------------------------\n",
    "# Set Up Players and Tournament\n",
    "# -------------------------------\n",
    "\n",
    "# Assuming player names are defined as follows:\n",
    "names = [\"apple\", \"banana\", \"cantaloupe\", \"durian\"]\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Run Tournament and Collect Stats\n",
    "# -------------------------------\n",
    "\n",
    "num_games = 1000\n",
    "# Dictionary to accumulate total chips for each player over all games.\n",
    "total_chip_counts = {name: 0 for name in names}\n",
    "\n",
    "for game_num in tqdm(range(num_games)):\n",
    "    # Create players.\n",
    "    # Player 0 will be the RL (trainable) player,\n",
    "    # and players 1-3 will be static (using the fixed model).\n",
    "    players = []\n",
    "    players.append(SupervisedPlayerWithOrderBook(0, names[0], rl_model, tokenizer, verbose=False))\n",
    "    for i in range(1, 4):\n",
    "        players.append(SupervisedPlayerWithOrderBook(i, names[i], static_model, tokenizer, verbose=False, override_name=names[i]))\n",
    "    # Create a new game instance with a fresh state.\n",
    "    game = Game(num_players=4, players=players)\n",
    "    game.run_game()  # This runs the game simulation.\n",
    "    logs.append(game.export_game_log())\n",
    "    # Retrieve the final public state of the game.\n",
    "    # We assume `get_public_state()` returns a dict with a \"players\" key,\n",
    "    # where each entry is like: {\"chips\": <chip_count>, ...}.\n",
    "    public_state = game.get_public_state()\n",
    "\n",
    "    print(f\"\\nGame {game_num + 1} final chip values:\")\n",
    "    for i in range(4):\n",
    "        chips = players[i].chips\n",
    "        print(f\"{names[i]}: {chips}\")\n",
    "        total_chip_counts[names[i]] += chips\n",
    "    winners.append(game.goal_suit_winner)\n",
    "    lengths.append(len(game.turn_history))\n",
    "    chip_vals.append([players[0].chips, players[1].chips, players[2].chips, players[3].chips])\n",
    "\n",
    "# Calculate and print average chip counts over all games.\n",
    "print(\"\\nAverage chip values over {} games:\".format(num_games))\n",
    "for name in names:\n",
    "    avg_chips = total_chip_counts[name] / num_games\n",
    "    print(f\"{name}: {avg_chips}\")\n",
    "\n",
    "print(lengths)\n",
    "print(chip_vals)\n",
    "print(winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7218307-5e0f-4d06-961d-84fc17686bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from tqdm import tqdm\n",
    "lengths = []\n",
    "chip_vals = []\n",
    "winners = []\n",
    "logs = []\n",
    "# rl_model_path = \"/content/drive/MyDrive/checkpoint-4000-new-tokenizer\"\n",
    "rl_model_path = \"aux_block_200\"\n",
    "rl_model = AutoModelForCausalLMWithValueHead.from_pretrained(rl_model_path).to(\"cuda\")\n",
    "\n",
    "# Load the static model (for the other three players) from the usual checkpoint.\n",
    "static_model_path = \"checkpoint-4000-new-tokenizer\"\n",
    "static_model = AutoModelForCausalLMWithValueHead.from_pretrained(static_model_path).to(\"cuda\")\n",
    "# Here we assume the tokenizer is the same (or similar) for both.\n",
    "# If needed, you could also load a separate tokenizer:\n",
    "# static_tokenizer = PreTrainedTokenizerFast.from_pretrained(static_model_path)\n",
    "# For this example, we will use the RL tokenizer for all players.\n",
    "\n",
    "# -------------------------------\n",
    "# Set Up Players and Tournament\n",
    "# -------------------------------\n",
    "\n",
    "# Assuming player names are defined as follows:\n",
    "names = [\"apple\", \"banana\", \"cantaloupe\", \"durian\"]\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Run Tournament and Collect Stats\n",
    "# -------------------------------\n",
    "\n",
    "num_games = 1000\n",
    "# Dictionary to accumulate total chips for each player over all games.\n",
    "total_chip_counts = {name: 0 for name in names}\n",
    "\n",
    "for game_num in tqdm(range(num_games)):\n",
    "    # Create players.\n",
    "    # Player 0 will be the RL (trainable) player,\n",
    "    # and players 1-3 will be static (using the fixed model).\n",
    "    players = []\n",
    "    players.append(SupervisedPlayerWithOrderBook(0, names[0], rl_model, tokenizer, verbose=False))\n",
    "    for i in range(1, 4):\n",
    "        players.append(SupervisedPlayerWithOrderBook(i, names[i], static_model, tokenizer, verbose=False, override_name=names[i]))\n",
    "    # Create a new game instance with a fresh state.\n",
    "    game = Game(num_players=4, players=players)\n",
    "    game.run_game()  # This runs the game simulation.\n",
    "    logs.append(game.export_game_log())\n",
    "    # Retrieve the final public state of the game.\n",
    "    # We assume `get_public_state()` returns a dict with a \"players\" key,\n",
    "    # where each entry is like: {\"chips\": <chip_count>, ...}.\n",
    "    public_state = game.get_public_state()\n",
    "\n",
    "    print(f\"\\nGame {game_num + 1} final chip values:\")\n",
    "    for i in range(4):\n",
    "        chips = players[i].chips\n",
    "        print(f\"{names[i]}: {chips}\")\n",
    "        total_chip_counts[names[i]] += chips\n",
    "    winners.append(game.goal_suit_winner)\n",
    "    lengths.append(len(game.turn_history))\n",
    "    chip_vals.append([players[0].chips, players[1].chips, players[2].chips, players[3].chips])\n",
    "\n",
    "# Calculate and print average chip counts over all games.\n",
    "print(\"\\nAverage chip values over {} games:\".format(num_games))\n",
    "for name in names:\n",
    "    avg_chips = total_chip_counts[name] / num_games\n",
    "    print(f\"{name}: {avg_chips}\")\n",
    "\n",
    "print(lengths)\n",
    "print(chip_vals)\n",
    "print(winners)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
